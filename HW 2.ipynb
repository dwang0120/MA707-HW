{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7aa4dc",
   "metadata": {},
   "source": [
    "## HW 2\n",
    "\n",
    "Dennis Wang\n",
    "\n",
    "MA 707 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16a9ec",
   "metadata": {},
   "source": [
    "Find a dataset (from sklearn, seaborn, https://datasetsearch.research.google.com/, or anywhere else), choose features and a categorical target, impute missing entries if needed, split 80/20 into training and test, then fit the following models on your training data and report their accuracies on the test data: random forest, Gaussian Naive Bayes, SVM. Try this once without rescaling your data, once when normalizing it, and once when standardizing it (remember when you rescale to only do it on the feature matrix X not the target vector y, and also to fit the rescale on your training data then use it to transform the test data).\n",
    "\n",
    "NOTES: \n",
    "\n",
    "(1) You may need to convert numerical features to categorical or categorical features to numerical depending on the method---you decide what should be done in this regard and do it. \n",
    "\n",
    "(2) For methods that involve hyperparameters, just pick and try a few values by hand and use whatever gives the best test accuracy (you don't have to do a thorough grid search, though you can if you want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee267af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c82d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bed83b",
   "metadata": {},
   "source": [
    "### Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d2bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "\n",
    "    if pd.isnull(Age):\n",
    "        if Pclass == 1:\n",
    "            return round(titanic[titanic['pclass'] == 1]['age'].dropna().mean()) # the average for 1st class\n",
    "        elif Pclass == 2:\n",
    "            return round(titanic[titanic['pclass'] == 2]['age'].dropna().mean()) # the average for 2nd class\n",
    "        else:\n",
    "            return round(titanic[titanic['pclass'] == 3]['age'].dropna().mean()) # the average for 3rd class\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a374137a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['age'] = titanic[['age', 'pclass']].apply(impute_age, axis = 1)\n",
    "titanic['age'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347767cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eda6ec",
   "metadata": {},
   "source": [
    "### Vectorization of Dummy Variabes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a516a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.get_dummies(titanic, columns = ['sex', 'embarked'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54643918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survived  pclass   age  sibsp  parch     fare  class    who  adult_male  \\\n",
       "1          1       1  38.0      1      0  71.2833  First  woman       False   \n",
       "3          1       1  35.0      1      0  53.1000  First  woman       False   \n",
       "6          0       1  54.0      0      0  51.8625  First    man        True   \n",
       "10         1       3   4.0      1      1  16.7000  Third  child       False   \n",
       "11         1       1  58.0      0      0  26.5500  First  woman       False   \n",
       "\n",
       "   deck  embark_town alive  alone  sex_male  embarked_Q  embarked_S  \n",
       "1     C    Cherbourg   yes  False         0           0           0  \n",
       "3     C  Southampton   yes  False         0           0           1  \n",
       "6     E  Southampton    no   True         1           0           1  \n",
       "10    G  Southampton   yes  False         0           0           1  \n",
       "11    C  Southampton   yes   True         0           0           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4500add",
   "metadata": {},
   "source": [
    "### Split 80/20 into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80d2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['pclass','age','sibsp','parch','fare', 'sex_male', 'embarked_Q', 'embarked_S']]\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be00293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf9e32",
   "metadata": {},
   "source": [
    "### Fitting Models - No rescaling\n",
    "\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33ad748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4ee3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc77a2",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae16b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e941fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24601834",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a70c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2af96f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    "grid = GridSearchCV(svm.SVC(), param_grid = param_grid, return_train_score = True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7becc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean cross-validation score: 0.66875\n",
      "Best parameters: {'C': 10}\n",
      "Test-set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6d687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(C = grid.best_params_.get('C'))\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4f03f",
   "metadata": {},
   "source": [
    "####  Model Evaluation - No Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36737fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f60e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[[ 5  7]\n",
      " [ 2 27]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.53        12\n",
      "           1       0.79      0.93      0.86        29\n",
      "\n",
      "    accuracy                           0.78        41\n",
      "   macro avg       0.75      0.67      0.69        41\n",
      "weighted avg       0.77      0.78      0.76        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print(confusion_matrix(rfc_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(rfc_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a64953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "[[ 6  9]\n",
      " [ 1 25]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.55        15\n",
      "           1       0.74      0.96      0.83        26\n",
      "\n",
      "    accuracy                           0.76        41\n",
      "   macro avg       0.80      0.68      0.69        41\n",
      "weighted avg       0.78      0.76      0.73        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes')\n",
    "print(confusion_matrix(gnb_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(gnb_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a9bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "[[ 0  4]\n",
      " [ 7 30]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.88      0.81      0.85        37\n",
      "\n",
      "    accuracy                           0.73        41\n",
      "   macro avg       0.44      0.41      0.42        41\n",
      "weighted avg       0.80      0.73      0.76        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SVM')\n",
    "print(confusion_matrix(svm_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(svm_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541daadc",
   "metadata": {},
   "source": [
    "### Fitting models - Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e3bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c392821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.558513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.829376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006346</td>\n",
       "      <td>0.368053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089013</td>\n",
       "      <td>0.741773</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.425177</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904990</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014178</td>\n",
       "      <td>0.666352</td>\n",
       "      <td>0.014178</td>\n",
       "      <td>0.014178</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass       age     sibsp     parch      fare  sex_male  embarked_Q  \\\n",
       "0  0.009973  0.558513  0.000000  0.009973  0.829376  0.000000         0.0   \n",
       "1  0.006346  0.368053  0.000000  0.000000  0.929783  0.000000         0.0   \n",
       "2  0.089013  0.741773  0.029671  0.029671  0.663392  0.000000         0.0   \n",
       "3  0.008504  0.425177  0.008504  0.000000  0.904990  0.008504         0.0   \n",
       "4  0.014178  0.666352  0.014178  0.014178  0.745098  0.000000         0.0   \n",
       "\n",
       "   embarked_S  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.014178  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train) # fit to data, not the target class\n",
    "norm_features = normalizer.transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "\n",
    "X_tr_norm = pd.DataFrame(norm_features, columns = X_train.columns)\n",
    "X_tr_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a54f4a",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "913176ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_tr_norm, y_train)\n",
    "rfc_norm_predictions = rfc.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68119e28",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a4897ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_tr_norm, y_train)\n",
    "gnb_norm_predictions = gnb.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba1803",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b01f3553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_tr_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98364210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean cross-validation score: 0.6625\n",
      "Best parameters: {'C': 10}\n",
      "Test-set score: 0.171\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f2ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(C = grid.best_params_.get('C'))\n",
    "svm_model.fit(X_tr_norm, y_train)\n",
    "svm_norm_predictions = svm_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62c3b5",
   "metadata": {},
   "source": [
    "#### Model Evaluation - Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aabb8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Normalized\n",
      "[[ 4  6]\n",
      " [ 3 28]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.40      0.47        10\n",
      "           1       0.82      0.90      0.86        31\n",
      "\n",
      "    accuracy                           0.78        41\n",
      "   macro avg       0.70      0.65      0.67        41\n",
      "weighted avg       0.76      0.78      0.77        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest - Normalized')\n",
    "print(confusion_matrix(rfc_norm_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(rfc_norm_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28d4d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - Normalized\n",
      "[[ 1  3]\n",
      " [ 6 31]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.25      0.18         4\n",
      "           1       0.91      0.84      0.87        37\n",
      "\n",
      "    accuracy                           0.78        41\n",
      "   macro avg       0.53      0.54      0.53        41\n",
      "weighted avg       0.84      0.78      0.81        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes - Normalized')\n",
    "print(confusion_matrix(gnb_norm_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(gnb_norm_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b249d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Normalized\n",
      "[[ 0  1]\n",
      " [ 7 33]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.97      0.82      0.89        40\n",
      "\n",
      "    accuracy                           0.80        41\n",
      "   macro avg       0.49      0.41      0.45        41\n",
      "weighted avg       0.95      0.80      0.87        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SVM - Normalized')\n",
    "print(confusion_matrix(svm_norm_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(svm_norm_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8522c2",
   "metadata": {},
   "source": [
    "### Fitting Models - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4affcd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdb85e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.412751</td>\n",
       "      <td>1.303612</td>\n",
       "      <td>-0.660979</td>\n",
       "      <td>0.797861</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>-1.119608</td>\n",
       "      <td>-0.138233</td>\n",
       "      <td>-1.308382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.412751</td>\n",
       "      <td>1.433991</td>\n",
       "      <td>-0.660979</td>\n",
       "      <td>-0.589723</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>-1.119608</td>\n",
       "      <td>-0.138233</td>\n",
       "      <td>-1.308382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.063047</td>\n",
       "      <td>-0.717252</td>\n",
       "      <td>1.101632</td>\n",
       "      <td>0.797861</td>\n",
       "      <td>-0.648935</td>\n",
       "      <td>-1.119608</td>\n",
       "      <td>-0.138233</td>\n",
       "      <td>-1.308382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.412751</td>\n",
       "      <td>0.912477</td>\n",
       "      <td>1.101632</td>\n",
       "      <td>-0.589723</td>\n",
       "      <td>0.452272</td>\n",
       "      <td>0.893170</td>\n",
       "      <td>-0.138233</td>\n",
       "      <td>-1.308382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412751</td>\n",
       "      <td>0.716910</td>\n",
       "      <td>1.101632</td>\n",
       "      <td>0.797861</td>\n",
       "      <td>-0.253393</td>\n",
       "      <td>-1.119608</td>\n",
       "      <td>-0.138233</td>\n",
       "      <td>0.764303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass       age     sibsp     parch      fare  sex_male  embarked_Q  \\\n",
       "0 -0.412751  1.303612 -0.660979  0.797861  0.147497 -1.119608   -0.138233   \n",
       "1 -0.412751  1.433991 -0.660979 -0.589723  0.977495 -1.119608   -0.138233   \n",
       "2  3.063047 -0.717252  1.101632  0.797861 -0.648935 -1.119608   -0.138233   \n",
       "3 -0.412751  0.912477  1.101632 -0.589723  0.452272  0.893170   -0.138233   \n",
       "4 -0.412751  0.716910  1.101632  0.797861 -0.253393 -1.119608   -0.138233   \n",
       "\n",
       "   embarked_S  \n",
       "0   -1.308382  \n",
       "1   -1.308382  \n",
       "2   -1.308382  \n",
       "3   -1.308382  \n",
       "4    0.764303  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) # fit to data, not the target class\n",
    "scaled_features = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_tr_scaled = pd.DataFrame(scaled_features, columns = X_train.columns)\n",
    "X_tr_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37469b9",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10da42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_tr_scaled, y_train)\n",
    "rfc_scaled_predictions = rfc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1ebf6",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc535106",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_tr_scaled, y_train)\n",
    "gnb_scaled_predictions = gnb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c3d8c",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43596d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10, 1, 0.1, 0.01, 0.001, 0.0001, 1e-05]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40661b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean cross-validation score: 0.725\n",
      "Best parameters: {'C': 1}\n",
      "Test-set score: 0.829\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d10edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(C = grid.best_params_.get('C'))\n",
    "svm_model.fit(X_tr_scaled, y_train)\n",
    "svm_scaled_predictions = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5050a0a",
   "metadata": {},
   "source": [
    "#### Model Evaluation - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3b6a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Scaled\n",
      "[[ 5  8]\n",
      " [ 2 26]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.38      0.50        13\n",
      "           1       0.76      0.93      0.84        28\n",
      "\n",
      "    accuracy                           0.76        41\n",
      "   macro avg       0.74      0.66      0.67        41\n",
      "weighted avg       0.75      0.76      0.73        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest - Scaled')\n",
    "print(confusion_matrix(rfc_scaled_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(rfc_scaled_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b4e7b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes - Scaled\n",
      "[[ 6  9]\n",
      " [ 1 25]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.40      0.55        15\n",
      "           1       0.74      0.96      0.83        26\n",
      "\n",
      "    accuracy                           0.76        41\n",
      "   macro avg       0.80      0.68      0.69        41\n",
      "weighted avg       0.78      0.76      0.73        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes - Scaled')\n",
    "print(confusion_matrix(gnb_scaled_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(gnb_scaled_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abb6619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Scaled\n",
      "[[ 6  7]\n",
      " [ 1 27]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.46      0.60        13\n",
      "           1       0.79      0.96      0.87        28\n",
      "\n",
      "    accuracy                           0.80        41\n",
      "   macro avg       0.83      0.71      0.74        41\n",
      "weighted avg       0.81      0.80      0.79        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SVM - Scaled')\n",
    "print(confusion_matrix(svm_scaled_predictions, y_test))\n",
    "print('\\n')\n",
    "print(classification_report(svm_scaled_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2521b9",
   "metadata": {},
   "source": [
    "### Conceptual Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d458585",
   "metadata": {},
   "source": [
    "#### From Sep 15 lecture:\n",
    "\n",
    ">Describe in words the \"backwards elimination\" process for feature selection\n",
    "\n",
    "When selecting which features to include in your model, backwards eliminations involves starting with a model with all the features included, and then eliminating the feature that leads to the the model with the best accuracy score. Keep eliminating features and creating new models until you no longer get better accuracy scores.\n",
    "\n",
    ">Explain why some categorical variables need to be vectorized (one-hot encoding) whereas others can be label encoded (just assigned a different number for each value)\n",
    "\n",
    "If there is an implicit order to the categorical variable, e.g. the darkness level of a crab shell sorted as Dark, Medium Dark, Medium, etc., then it can be assigned a different number for each value and the number would correspond to that implicit order. However, if there is no implicit order to the categorical variable, such as the state that a package is shipped to, then there is no way to judge whether one state is greater than another (e.g. NJ > MA), and thus the variable will need to be vectorized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a6397",
   "metadata": {},
   "source": [
    "#### k-NN:\n",
    "\n",
    ">How does k-NN label new data points based on the training data points (both for classification and for regression)?\n",
    "\n",
    ">What effect does the hyperparmater k have?\n",
    "\n",
    "The hyperparameter k is how many of the closest k points to our test data point will be considered in our judgement. Smaller k-values make the model more complex and sensitive to the local region of our test value, but increase the risk of overfitting. Therefore, if we think the local structure of our data points are important, then a smaller K is better. Bigger K-values are more representative of our overall dataset but less sensitive to local regions of the data, which may also be bad.\n",
    "\n",
    "In classification, we simply take the majority label of our k neighbors and select that as the prediction for our test data point. In regression, we take the mean of all the k neighbors and choose that as our prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedf007",
   "metadata": {},
   "source": [
    "#### Naive Bayes:\n",
    "\n",
    "How does Bayes formula help with classification if we've already estimated the probability distribution for each class?\n",
    "\n",
    "Explain how the class distributions are estimated in Gaussian Naive Bayes\n",
    "\n",
    "Very roughly, what are Gaussian Mixture Model (GMM) and Kernel Density Estim-tor (KDE)?\n",
    "\n",
    "Describe Naive Bayes classification when all predictors are discrete (this is the frequency-based version) including what the \"Naive\" part of it means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335d0cd",
   "metadata": {},
   "source": [
    "#### Decision trees and random forest:\n",
    "\n",
    ">Explain the basic idea of a decision tree and what kind of decision boundary it produces\n",
    "\n",
    "How are random forests related to decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97feeaa1",
   "metadata": {},
   "source": [
    "#### SVM:\n",
    "\n",
    ">Explain the basic idea and how the cost parameter C is used and what it does (no need to explain anything about kernels or radial basis functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8e6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
